{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5804264f",
   "metadata": {},
   "source": [
    "EnbPI Bootstrap Steps:\n",
    "1) Extract and Clean Data\n",
    "2) Preprocess Data\n",
    "3) Bootstrap Synthetic Data\n",
    "4) Train Bootstrap Models\n",
    "5) LOO Predict and Mean Aggregate\n",
    "6) Get Conformal Prediction Interval \n",
    "7) Get Coverage Rate on Test\n",
    "8) Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8833fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6dd6ef-df83-47b5-9ca1-7e8cf5d6cfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Step 1) Extract and Clean Data\n",
    "def read_data(data_name, max_data_size):\n",
    "    data_dir = \"./Data\"\n",
    "\n",
    "    if data_name == \"Solar_Atl\":\n",
    "        \"\"\"\n",
    "        4 (Alternative). NREL Solar data at Atlanta Downtown in 2018.\n",
    "            - 24 observations per day and separately equally by 1H @ half an hour mark everytime\n",
    "        Data descriptions see Solar Writeup\n",
    "        Data download:\n",
    "        (With API) https://nsrdb.nrel.gov/data-sets/api-instructions.html\n",
    "        (Manual) https://maps.nrel.gov/nsrdb-viewer\n",
    "        Properties:\n",
    "            - Type: multivariate (5 temporal columns, 7 feature columns, 1 target)\n",
    "            - Length: 8760\n",
    "            - Period: entire 2018\n",
    "            - Frequency: hourly (at every 30-min mark)\n",
    "        \"\"\"\n",
    "        file_name = f\"{data_dir}/{data_name}_data.csv\"\n",
    "        data_df = pd.read_csv(file_name, skiprows=2)\n",
    "        # data_df.shape  # 8760, 14\n",
    "        data_df.drop(columns=data_df.columns[0:5], inplace=True)  # remove 5 temporal columns\n",
    "        data_df.drop(columns=\"Unnamed: 13\", inplace=True)\n",
    "        # data_df.shape  # 8760, 8\n",
    "        target_column = \"DHI\"\n",
    "\n",
    "    elif data_name in _get_cali_cities():  # \"Palo_Alto\"\n",
    "        \"\"\"\n",
    "        Properties:\n",
    "            - Type: multivariate (1 datetime index, 5 temporal columns, 7 feature columns, 1 target)\n",
    "            - Length: 8760\n",
    "            - Period: entire 2018\n",
    "            - Frequency: hourly\n",
    "        \"\"\"\n",
    "        file_name = f\"{data_dir}/{data_name}_data.csv\"\n",
    "        data_df = pd.read_csv(file_name)\n",
    "        data_df.drop(columns=data_df.columns[0:6], inplace=True)  # remove datetime index and 5 temporal columns\n",
    "        target_column = \"DHI\"\n",
    "\n",
    "    elif data_name == \"appliances\":\n",
    "        \"\"\"\n",
    "        2. Appliances energy prediction Data Set\n",
    "        The data set is at 10 min for about 4.5 months.\n",
    "        The column named 'Appliances' is the response. Other columns are predictors\n",
    "        https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\n",
    "        Properties:\n",
    "            - Type: multivariate (1 temporal column, 27 feature columns, 1 target)\n",
    "            - Length: 19735\n",
    "            - Period: 2016-01-11 @5PM to 2016-05-27 @6PM\n",
    "            - Frequency: every 10-min\n",
    "        \"\"\"\n",
    "        file_name = f\"{data_dir}/{data_name}_data.csv\"\n",
    "        data_df = pd.read_csv(file_name, delimiter=\",\")\n",
    "        # data_df.shape  # (19736, 29)\n",
    "        data_df.drop(\"date\", inplace=True, axis=1)  # remove the temporal column\n",
    "        data_df.loc[:, data_df.columns != \"Appliances\"]\n",
    "        target_column = \"Appliances\"\n",
    "\n",
    "    elif data_name == \"green_house\":\n",
    "        \"\"\"\n",
    "        All datasets are Multivariate time-series. They have respective Github for more details as well.\n",
    "        1. Greenhouse Gas Observing Network Data Set\n",
    "        Time from 5.10-7.31, 2010, with 4 samples everyday, 6 hours apart between data poits.\n",
    "        Goal is to \"use inverse methods to determine the optimal values of the weights in the weighted sum of 15 tracers that best matches the synthetic observations\"\n",
    "        In other words, find weights so that first 15 tracers will be as close to the last as possible.\n",
    "        Note, data at many other grid cells are available. Others are in Downloads/ðŸŒŸAISTATS Data/Greenhouse Data\n",
    "        https://archive.ics.uci.edu/ml/datasets/Greenhouse+Gas+Observing+Network\n",
    "        Properties:\n",
    "            - Type: multivariate (15 feature columns aka tracers(?), 1 target)\n",
    "            - Length: 327\n",
    "            - Period: 2010-05-10 to 2010-07-31\n",
    "            - Frequency: every 6-hours\n",
    "        \"\"\"\n",
    "        file_name = f\"{data_dir}/{data_name}_data.csv\"\n",
    "        data_df = pd.read_csv(file_name, header=None, sep=\" \").T\n",
    "        # data_df.shape  # 327, 16 Note, rows are 16 time series (first 15 from tracers, last from synthetic).\n",
    "        target_column = 15\n",
    "\n",
    "    elif data_name == \"Beijing_air\":\n",
    "        \"\"\"\n",
    "        3. Beijing Multi-Site Air-Quality Data Data Set\n",
    "        This data set includes hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites.\n",
    "        Time period from 3.1, 2013 to 2.28, 2017.\n",
    "        PM2.5 or PM10 would be the response.\n",
    "        https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data\n",
    "        Properties:\n",
    "            - Type: multivariate (1 index, 4 temporal columns, 12 feature columns, 1 target)\n",
    "            - Length: 35064\n",
    "            - Period: 2013-03-01 to 2017-02-28\n",
    "            - Frequency: hourly\n",
    "        \"\"\"\n",
    "        file_name = f\"{data_dir}/{data_name}_Tiantan_data.csv\"\n",
    "        data_df = pd.read_csv(file_name)\n",
    "        # data_df.shape  # 35064, 18\n",
    "        data_df.drop(\n",
    "            columns=[\"No\", \"year\", \"month\", \"day\", \"hour\", \"wd\", \"station\"],\n",
    "            inplace=True,\n",
    "            axis=1,\n",
    "        )\n",
    "        data_df.dropna(inplace=True)\n",
    "        # data_df.shape  # 32907, 11\n",
    "        target_column = \"PM2.5\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"data_name not found\")   \n",
    "\n",
    "\n",
    "    # pick maximum of X data points (for speed)\n",
    "    data_df = data_df.iloc[: min(max_data_size, data_df.shape[0]), :]\n",
    "    # shift target column back by one (for single-step forecast)\n",
    "    data_df[target_column] = data_df[target_column].shift(-1)\n",
    "    # remove final row as it does not contain target column value anymore\n",
    "    data_df = data_df.iloc[:-1 , :]        \n",
    "\n",
    "    return data_df, target_column\n",
    "\n",
    "\n",
    "def _get_cali_cities():\n",
    "    cali_cities = [\n",
    "        \"Fremont\",\n",
    "        \"Milpitas\",\n",
    "        \"Mountain_View\",\n",
    "        \"North_San_Jose\",\n",
    "        \"Palo_Alto\",\n",
    "        \"Redwood_City\",\n",
    "        \"San_Mateo\",\n",
    "        \"Santa_Clara\",\n",
    "        \"Sunnyvale\",\n",
    "    ]\n",
    "    return cali_cities\n",
    "\n",
    "\n",
    "# Step 2) this is the AR-transformer. can replace with something from sktime.  ################\n",
    "def one_dimen_transform(y_train, y_test, n_lags):\n",
    "    n = len(y_train)\n",
    "    n1 = len(y_test)\n",
    "    X_train = np.zeros((n - n_lags, n_lags))  # from n_lags+1,...,n\n",
    "    X_test = np.zeros((n1, n_lags))  # from n-n_lags,...,n+n1-n_lags\n",
    "    for i in range(n - n_lags):\n",
    "        X_train[i, :] = y_train[i : i + n_lags]\n",
    "    for i in range(n1):\n",
    "        if i < n_lags:\n",
    "            X_test[i, :] = np.r_[y_train[n - n_lags + i :], y_test[:i]]\n",
    "        else:\n",
    "            X_test[i, :] = y_test[i - n_lags : i]\n",
    "    y_train = y_train[n_lags:]\n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "\n",
    "\n",
    "# Step 3) ################\n",
    "def generate_bootstrap_samples(n, m, B, bootstrap_type, block_length, random_seed):\n",
    "    samples_idx = np.zeros((B, m), dtype=int)\n",
    "\n",
    "    for b in range(B):\n",
    "        if bootstrap_type == \"random\":  # RB\n",
    "            np.random.seed(b + random_seed)\n",
    "            sample_idx = np.random.choice(a=n, size=m, replace=True)\n",
    "        elif bootstrap_type == \"nonoverlapping\":  # NBB\n",
    "            sample_idx = _id_nbb_bootstrap(\n",
    "                n_obs=n, block_length=block_length, random_seed=b + random_seed,\n",
    "            )\n",
    "        elif bootstrap_type == \"moving\":  # MBB\n",
    "            sample_idx = _id_mbb_bootstrap(\n",
    "                n_obs=n, block_length=block_length, random_seed=b + random_seed,\n",
    "            )\n",
    "        elif bootstrap_type == \"circular\":  # CBB\n",
    "            sample_idx = _id_cbb_bootstrap(\n",
    "                n_obs=n, block_length=block_length, random_seed=b + random_seed,\n",
    "            )\n",
    "        elif bootstrap_type == \"stationary\":  # SBB\n",
    "            sample_idx = _id_sbb_bootstrap(\n",
    "                n_obs=n, block_length=block_length, random_seed=b + random_seed,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"boostrap_type not supported\")      \n",
    "        samples_idx[b, :] = sample_idx\n",
    "\n",
    "    return samples_idx\n",
    "\n",
    "\n",
    "# Non-overlapping block bootstrap (NBB)\n",
    "def _id_nbb_bootstrap(\n",
    "    n_obs: int, block_length: int, random_seed: Optional[int] = 10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create bootstrapped indexes with the none overlapping block bootstrap\n",
    "    ('nbb') strategy given the number of observations in a timeseries and\n",
    "    the length of the blocks.\n",
    "    Returns\n",
    "    -------\n",
    "    _id : array\n",
    "        Bootstrapped indexes.\n",
    "    \"\"\"\n",
    "    rng = default_rng(random_seed)\n",
    "    \n",
    "    n_blocks = int(np.ceil(n_obs / block_length))\n",
    "    nexts = np.repeat([np.arange(0, block_length)], n_blocks, axis=0)\n",
    "    \n",
    "    blocks = rng.permutation(x=np.arange(0, n_obs, block_length)).reshape(-1, 1)\n",
    "    _id = (blocks + nexts).ravel()[:n_obs]\n",
    "\n",
    "    return _id\n",
    "\n",
    "\n",
    "# Moving block bootstrap (MBB)\n",
    "def _id_mbb_bootstrap(\n",
    "    n_obs: int, block_length: int, random_seed: Optional[int]=10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create bootstrapped indexes with the moving block bootstrap\n",
    "    ('mbb') strategy given the number of observations in a timeseries\n",
    "    and the length of the blocks.\n",
    "    Returns\n",
    "    -------\n",
    "    _id : array\n",
    "        Bootstrapped indexes.\n",
    "    \"\"\"\n",
    "    rng = default_rng(random_seed)\n",
    "    try:\n",
    "        rng_integers = rng.integers\n",
    "    except AttributeError:\n",
    "        rng_integers = rng.randint\n",
    "\n",
    "    n_blocks = int(np.ceil(n_obs / block_length))\n",
    "    nexts = np.repeat([np.arange(0, block_length)], n_blocks, axis=0)\n",
    "    \n",
    "    last_block = n_obs - block_length\n",
    "    blocks = rng_integers(low=0, high=last_block, size=(n_blocks, 1), dtype=int)\n",
    "    _id = (blocks + nexts).ravel()[:n_obs]\n",
    "\n",
    "    return _id\n",
    "\n",
    "\n",
    "# Circular block bootstrap (MBB)\n",
    "def _id_cbb_bootstrap(\n",
    "    n_obs: int, block_length: int, random_seed: Optional[int]=10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create bootstrapped indexes with the circular block bootstrap\n",
    "    ('cbb') strategy given the number of observations in a timeseries\n",
    "    and the length of the blocks.\n",
    "    Returns\n",
    "    -------\n",
    "    _id : array\n",
    "        Bootstrapped indexes.\n",
    "    \"\"\"\n",
    "    rng = default_rng(random_seed)\n",
    "    try:\n",
    "        rng_integers = rng.integers\n",
    "    except AttributeError:\n",
    "        rng_integers = rng.randint\n",
    "\n",
    "    n_blocks = int(np.ceil(n_obs / block_length))\n",
    "    nexts = np.repeat([np.arange(0, block_length)], n_blocks, axis=0)\n",
    "    \n",
    "    last_block = n_obs\n",
    "    blocks = rng_integers(low=0, high=last_block, size=(n_blocks, 1), dtype=int)\n",
    "    _id = np.mod((blocks + nexts).ravel(), n_obs)[:n_obs]\n",
    "\n",
    "    return _id\n",
    "\n",
    "\n",
    "# Stationary block bootstrap (SBB)\n",
    "def _id_sbb_bootstrap(\n",
    "    n_obs: int, block_length: int, random_seed: Optional[int]=10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create bootstrapped indexes with the stationary block bootstrap\n",
    "    ('sb') strategy given the number of observations in a timeseries\n",
    "    and the length of the blocks.\n",
    "    Returns\n",
    "    -------\n",
    "    _id : array\n",
    "        Bootstrapped indexes.\n",
    "    \"\"\"\n",
    "    rng = default_rng(random_seed)\n",
    "    try:\n",
    "        rng_integers = rng.integers\n",
    "    except AttributeError:\n",
    "        rng_integers = rng.randint\n",
    "    #\n",
    "    rng_poisson = rng.poisson\n",
    "    #\n",
    "    random_block_length = rng_poisson(lam=block_length, size=n_obs)\n",
    "    random_block_length[random_block_length < 3] = 3\n",
    "    random_block_length[random_block_length >= n_obs] = n_obs\n",
    "    random_block_length = random_block_length[random_block_length.cumsum() <= n_obs]\n",
    "    residual_block = n_obs - random_block_length.sum()\n",
    "    if residual_block > 0:\n",
    "        random_block_length = np.append(random_block_length, residual_block)\n",
    "    #\n",
    "    n_blocks = random_block_length.shape[0]\n",
    "    nexts = np.zeros((n_blocks, random_block_length.max() + 1))\n",
    "    nexts[np.arange(n_blocks), random_block_length] = 1\n",
    "    nexts = np.flip(nexts, 1).cumsum(1).cumsum(1).ravel()\n",
    "    nexts = (nexts[nexts > 1] - 2).astype(int)\n",
    "    #\n",
    "    last_block = n_obs - random_block_length.max()\n",
    "    blocks = np.zeros(n_obs, dtype=int)\n",
    "    if last_block > 0:\n",
    "        blocks = rng_integers(low=0, high=last_block, size=n_blocks)\n",
    "        blocks = np.repeat(blocks, random_block_length)\n",
    "    _id = blocks + nexts\n",
    "    #\n",
    "    return _id\n",
    "\n",
    "\n",
    "# Step 4) ################\n",
    "def initiate_regressor(model_type):\n",
    "    min_alpha = 0.0001\n",
    "    max_alpha = 10\n",
    "\n",
    "    if model_type == \"lasso\":\n",
    "        model = LassoCV(alphas=np.linspace(min_alpha, max_alpha, 10))\n",
    "    elif model_type == \"ridge\":\n",
    "        model = RidgeCV(alphas=np.linspace(min_alpha, max_alpha, 10))\n",
    "    elif model_type == \"random_forest\":\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=10,\n",
    "            criterion=\"squared_error\",\n",
    "            bootstrap=False,\n",
    "            max_depth=2,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    elif model_type == \"extra_trees\":\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=10,\n",
    "            criterion=\"squared_error\",\n",
    "            bootstrap=False,\n",
    "            max_depth=2,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type not supported\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c57b38-a089-444d-acbe-86fbdf842bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def binning(past_resid, alpha):\n",
    "    '''\n",
    "    Input:\n",
    "        past residuals: evident\n",
    "        alpha: signifance level\n",
    "    Output:\n",
    "        beta_hat_bin as argmin of the difference\n",
    "    Description:\n",
    "        Compute the beta^hat_bin from past_resid, by breaking [0,alpha] into bins (like 20). It is enough for small alpha\n",
    "        number of bins are determined rather automatic, relative the size of whole domain\n",
    "    '''\n",
    "    bins = 5  # For computation, can just reduce it to like 10 or 5 in real data\n",
    "    beta_ls = np.linspace(start=0, stop=alpha, num=bins)\n",
    "    width = np.zeros(bins)\n",
    "    for i in range(bins):\n",
    "        width[i] = np.percentile(past_resid, math.ceil(100 * (1 - alpha + beta_ls[i]))) - \\\n",
    "            np.percentile(past_resid, math.ceil(100 * beta_ls[i]))\n",
    "    i_star = np.argmin(width)\n",
    "    return beta_ls[i_star]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b8465-c697-45d8-8fee-81a0b00467bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.7  6.82 6.88 6.94 7.  ]\n",
      "[1.   1.12 1.18 1.24 1.3 ]\n",
      "[5.7 5.7 5.7 5.7 5.7]\n"
     ]
    }
   ],
   "source": [
    "resid = [1, 2, 3, 4, 5, 6, 7]\n",
    "alpha = 0.05\n",
    "bins = 5\n",
    "beta_ls = np.linspace(start=0, stop=alpha, num=bins)\n",
    "width = np.zeros(bins)\n",
    "upper_q = np.zeros(bins)\n",
    "lower_q = np.zeros(bins)\n",
    "#math.ceil(100 * (1 - alpha + beta_ls[0]))\n",
    "#math.ceil(100 * beta_ls[0])\n",
    "#np.percentile(resid, math.ceil(100 * (1 - alpha + beta_ls[0])))\n",
    "#np.percentile(resid, math.ceil(100 * beta_ls[0]))\n",
    "#np.percentile(resid, math.ceil(100 * (1 - alpha + beta_ls[0]))) - np.percentile(resid, math.ceil(100 * beta_ls[0]))\n",
    "for i in range(bins):\n",
    "        upper_q[i] = np.percentile(resid, math.ceil(100 * (1 - alpha + beta_ls[i])))\n",
    "        lower_q[i] = np.percentile(resid, math.ceil(100 * beta_ls[i]))\n",
    "        width[i] = upper_q[i] - lower_q[i]\n",
    "print(upper_q)\n",
    "print(lower_q)\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074777d",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828e61fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "# Step 1) params\n",
    "# cali_cities = [\"Palo_Alto\"]\n",
    "# data_list = _get_cali_cities()\n",
    "# data_list = [\"Solar_Atl\"] + cali_cities + [\"appliances\", \"Beijing_air\"]\n",
    "data_list = [\"Solar_Atl\"]\n",
    "max_data_size = 10000\n",
    "\n",
    "# Step 2) params\n",
    "# train_fractions = [0.1, 0.2]\n",
    "# train_fractions = [0.8001]\n",
    "train_fractions = [0.7, 0.8]\n",
    "# train_fractions = [0.3, 0.4, 0.5, 0.6, 0.7]  # EnbPI WP Pg. 8\n",
    "# print(train_fractions)\n",
    "# one_dim_list = [True]\n",
    "one_dim_list = [False]\n",
    "n_lags = 24  # 'n_lags' aka 'd` is num_lookbacks for AR-transformer\n",
    "\n",
    "# Step 3) params\n",
    "itrial = 0\n",
    "B_list = [30]  # number of bootstraps list\n",
    "# B_list = [20, 25, 30, 35, 40, 45, 50]  # EnbPI WP Pg. 11: between 20-50 is sufficient\n",
    "# bootstrap_types = [\"random\", \"moving\"]  # \"nonoverlapping\" has problem -> IndexError: index 851 is out of bounds for axis 0 with size 851\n",
    "bootstrap_types = [\"random\", \"moving\", \"circular\"]\n",
    "block_lengths = [6, 12, 24]\n",
    "# block_lengths = [6, 12, 24, 48, 60, 72]\n",
    "\n",
    "# Step 4) params\n",
    "# model_types = [\"ridge\", \"random_forest\"]  # muh_fun\n",
    "model_types = [\"lasso\", \"ridge\", \"random_forest\"]  # \"neural_networks\"\n",
    "method = \"Ensemble\"\n",
    "\n",
    "# Step 6) params\n",
    "alphas = [0.05, 0.1]\n",
    "# alphas = [0.05, 0.1, 0.15, 0.2, 0.25]  # EnbPI WP Pg. 17: five equally spaces 1-a [0.75, 0.95] are chosen\n",
    "# alphas = [0.01, 0.10, 0.20, 0.50, 0.80, 0.90, 0.99]\n",
    "# alphas = [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.50, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99]\n",
    "\n",
    "# Step 8) params\n",
    "output_name = \"Solar_Atl\"\n",
    "verbose = 1  # 0 no print statement, 1 only params, 2 everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9958771",
   "metadata": {},
   "source": [
    "# Original Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564752d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main executable function\n",
    "\n",
    "def enbpi_exec(\n",
    "    data_list,\n",
    "    max_data_size,\n",
    "    method,\n",
    "    train_fractions,\n",
    "    B_list,\n",
    "    bootstrap_types,\n",
    "    block_lengths,\n",
    "    model_types,\n",
    "    alphas,\n",
    "    itrial=0,\n",
    "    one_dim_list=[False],\n",
    "    n_lags=1,\n",
    "    output_name = \"many_data\",\n",
    "    verbose=1,\n",
    "):\n",
    "\n",
    "    # Step 1) Extract and Clean Data\n",
    "    for data_name in data_list:\n",
    "        if verbose >= 1: \n",
    "            print(\"\\n\\n\" + \"=\"*80)\n",
    "            print(f\"data_name='{data_name}'\")\n",
    "        data_df, target_column = read_data(data_name, max_data_size)\n",
    "        tab_str = \"- \"\n",
    "        if verbose == 2:\n",
    "            print(f\"{tab_str}data_name shape:{data_df.shape}\")\n",
    "            print(f\"{tab_str}target_column='{target_column}'\")\n",
    "\n",
    "        # STEP 2): Preprocess Data ################    \n",
    "        for one_dim in one_dim_list:\n",
    "            if verbose >= 1: print(f\"\\n{tab_str}one_dim={one_dim}\")\n",
    "            # Separate results output for one_dim True and False\n",
    "            results_df = pd.DataFrame()\n",
    "            # results_df = pd.DataFrame(columns=_get_results_columns())\n",
    "            for train_fraction in train_fractions:\n",
    "                tab_str = \"  \" + tab_str\n",
    "                if verbose >= 1: print(f\"\\n{tab_str}train_fraction={train_fraction}\")\n",
    "                # 2a) Split train/test sets\n",
    "                # get X and y data\n",
    "                data_X = data_df.drop(target_column, axis=1)\n",
    "                data_y = data_df[target_column]\n",
    "                # convert X and y data to numpy\n",
    "                data_X_numpy = data_X.to_numpy()\n",
    "                data_y_numpy = data_y.to_numpy()\n",
    "                # get train idx to split train and test\n",
    "                train_size = int(len(data_df) * train_fraction)\n",
    "                # split into 4\n",
    "                X_train_numpy = data_X_numpy[:train_size, :]\n",
    "                X_test_numpy = data_X_numpy[train_size:, :]\n",
    "                y_train_numpy = data_y_numpy[:train_size]\n",
    "                y_test_numpy = data_y_numpy[train_size:]\n",
    "                # 2b) Get AR coeffs (optional)\n",
    "                if one_dim:\n",
    "                    X_train, X_test, y_train, y_test = one_dimen_transform(\n",
    "                        y_train_numpy,\n",
    "                        y_test_numpy,\n",
    "                        n_lags=n_lags,  # d\n",
    "                    )\n",
    "                else:\n",
    "                    X_train = X_train_numpy.copy()\n",
    "                    X_test = X_test_numpy.copy()\n",
    "                    y_train = y_train_numpy.copy()\n",
    "                    y_test = y_test_numpy.copy()\n",
    "                tab_str = \"  \" + tab_str\n",
    "                if verbose == 2: \n",
    "                    print(f\"{tab_str}X_train shape: {X_train.shape}\")\n",
    "                    print(f\"{tab_str}X_test shape: {X_test.shape}\")\n",
    "                    print(f\"{tab_str}y_train shape: {y_train.shape}\")\n",
    "                    print(f\"{tab_str}y_test shape: {y_test.shape}\")\n",
    "\n",
    "                # STEP 3) Bootstrap Synthetic Data ################\n",
    "                for B in B_list:\n",
    "                    for bootstrap_type in bootstrap_types:\n",
    "                        for block_length in block_lengths:\n",
    "                            if verbose >= 1:\n",
    "                                print(f\"{tab_str}B={B}, bootstrap_type='{bootstrap_type}', block_length={block_length}\")\n",
    "                            n = len(X_train)\n",
    "                            n1 = len(X_test)\n",
    "                            m = n\n",
    "                            # tot_trial = 1    # For CP method that randomizes (for EnbPI, should be set to 1)\n",
    "                            itrial = itrial  # for tot_trial in range(tot_trial)\n",
    "                            random_seed = B + itrial\n",
    "                            boot_samples_idx = generate_bootstrap_samples(\n",
    "                                n=n,\n",
    "                                m=m,\n",
    "                                B=B,\n",
    "                                bootstrap_type=bootstrap_type,\n",
    "                                block_length=block_length,\n",
    "                                random_seed=random_seed,\n",
    "                            )\n",
    "                            tab_str = \"  \" + tab_str\n",
    "                            if verbose == 2: print(f\"{tab_str}Bootstrap samples indexes shape: {boot_samples_idx.shape}\")\n",
    "                            # print(boot_samples_idx)\n",
    "\n",
    "                            # STEP 4) Train Bootstrapped Models ################\n",
    "                            # tab_str = \"  \" + tab_str    \n",
    "                            for model_type in model_types:\n",
    "                                # if verbose >= 1: print(f\"{tab_str}model_type='{model_type}'\")\n",
    "                                # hold predictions from each f^b\n",
    "                                boot_predictions = np.zeros((B, (n + n1)), dtype=float)\n",
    "                                # for i^th column, it shows which f^b uses i in training (so exclude in aggregation)\n",
    "                                in_boot_sample = np.zeros((B, n), dtype=bool)\n",
    "                                for b in range(B):\n",
    "                                    X_train_boot = X_train[boot_samples_idx[b], :]\n",
    "                                    y_train_boot = y_train[boot_samples_idx[b],]\n",
    "                                    model = initiate_regressor(model_type)\n",
    "                                    model.fit(\n",
    "                                        X_train_boot,\n",
    "                                        y_train_boot,\n",
    "                                        # epochs=10,\n",
    "                                        # batch_size=bsize,\n",
    "                                        # callbacks=[callback],\n",
    "                                        # verbose=0,\n",
    "                                    )\n",
    "                                    # Model's prediction for every observation on every bootstrapped data\n",
    "                                    boot_predictions[b] = model.predict(np.r_[X_train, X_test]).flatten()\n",
    "                                    # Whether a observation in the training data is sampled for the given bootstrapped data\n",
    "                                    # If it is true, then this observation should NOT be used for model prediction\n",
    "                                    in_boot_sample[b, boot_samples_idx[b]] = True\n",
    "                                tab_str = \"  \" + tab_str\n",
    "                                if verbose == 2:\n",
    "                                    print(f\"{tab_str}boot_predictions shape: {boot_predictions.shape}\")\n",
    "                                    print(f\"{tab_str}in_boot_sample shape: {in_boot_sample.shape}\")\n",
    "\n",
    "                                # STEP 5) LOO Predict and Mean Aggregate\n",
    "                                y_in_pred = np.zeros(n)          # Mean aggregated predict on in-sample train set\n",
    "                                y_LOO_preds = np.zeros((n, n1))  # Non-aggregated predict on OOS test set\n",
    "                                y_pred = np.zeros(n1)            # Aggregated predict on OOS test set\n",
    "\n",
    "                                ensemble_online_resid = np.array([])    # LOO scores\n",
    "                                # LOO in-sample train predict and OOS test predict \n",
    "                                for i in range(n):\n",
    "                                    b_keep = np.argwhere(~(in_boot_sample[:, i])).reshape(-1)\n",
    "                                    if len(b_keep) > 0:\n",
    "                                        # Get the LOO predictions for i for both in-sample and OOS\n",
    "                                        y_train_LOO_boot_preds = boot_predictions[b_keep, i]\n",
    "                                        y_in_pred[i] = y_train_LOO_boot_preds.mean()  # Mean aggregate to form a scalar value\n",
    "                                        y_LOO_boot_preds = boot_predictions[b_keep, n:]\n",
    "                                        y_LOO_preds[i] = y_LOO_boot_preds.mean(0)\n",
    "                                    else:  # if aggregating an empty set of models, predict zero everywhere\n",
    "                                        if verbose == 2: print(f\"{tab_str}  WARNING: no bootstrapped models available for i={i}\")\n",
    "                                y_pred = y_LOO_preds.mean(0)\n",
    "                                if verbose == 2:\n",
    "                                    print(f\"{tab_str}y_in_pred shape: {y_in_pred.shape}\")\n",
    "                                    print(f\"{tab_str}y_pred shape: {y_pred.shape}\")\n",
    "                                    print(f\"{tab_str}  y_LOO_preds shape: {y_LOO_preds.shape}\")\n",
    "\n",
    "                                # STEP 6) Aggregate Model with LOO\n",
    "                                for alpha in alphas:\n",
    "                                    # if verbose >= 1: print(f\"{tab_str}alpha={alpha}\")\n",
    "                                    # Get absolute residual and sort\n",
    "                                    abs_resid = np.abs(np.subtract(y_train, y_in_pred))\n",
    "                                    abs_resid.sort()\n",
    "                                    # Get q-hat value\n",
    "                                    q_idx = int(-len(abs_resid)*alpha)\n",
    "                                    q_hat = abs_resid[q_idx]\n",
    "                                    # Evaluation metric 1: PI width\n",
    "                                    width = round(q_hat*2, 6)\n",
    "                                    tab_str = \"  \" + tab_str\n",
    "                                    if verbose == 2: print(f\"{tab_str}width={width}\")\n",
    "\n",
    "                                    # STEP 7) Get Coverage Rate from Test\n",
    "                                    # Get OOS absolute residual and sort\n",
    "                                    oos_abs_resid = np.abs(np.subtract(y_test, y_pred))\n",
    "                                    oos_abs_resid.sort()\n",
    "                                    # Count number of residuals below or equal to q_hat, or within the interval width.\n",
    "                                    n_coverage = np.asarray(oos_abs_resid <= q_hat).sum()\n",
    "                                    # Evaluation metric 2: Coverage rate\n",
    "                                    coverage = round(n_coverage/n1, 6)\n",
    "                                    if verbose == 2: print(f\"{tab_str}coverage={coverage}\")\n",
    "                                    \"\"\"\n",
    "                                    NOTE: I am using the symmetical conformal prediction (like in NP), instead of the\n",
    "                                          fancy method that Chen did. That is why the coverage rate is near the \n",
    "                                          theroretical guarantee limit of 2*alpha.\n",
    "                                    \"\"\"\n",
    "\n",
    "                                    #### STEP 8) Output Results\n",
    "                                    results_row = {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"one_dim\": one_dim,\n",
    "                                        \"itrial\": itrial,\n",
    "                                        \"train_fraction\": train_fraction,\n",
    "                                        \"B\": B,\n",
    "                                        \"bootstrap_type\": bootstrap_type,\n",
    "                                        \"block_length\": block_length,\n",
    "                                        \"model_type\": model.__class__.__name__,  # \"muh_fun\"\n",
    "                                        \"method\": method,\n",
    "                                        \"alpha\": alpha,\n",
    "                                        \"width\": width,    \n",
    "                                        \"coverage\": coverage,\n",
    "                                    }\n",
    "                                    results_df = pd.concat([results_df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "\n",
    "                                    tab_str = tab_str[2:]\n",
    "                                tab_str = tab_str[2:]\n",
    "                            tab_str = tab_str[2:]\n",
    "                tab_str = tab_str[4:]\n",
    "\n",
    "    results_df.to_csv(f'Results/{output_name}_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ef3f24-eba1-496d-857d-9cf0c6b33ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "data_name='Solar_Atl'\n",
      "\n",
      "- one_dim=False\n",
      "\n",
      "  - train_fraction=0.7\n",
      "    - B=30, bootstrap_type='random', block_length=6\n",
      "    - B=30, bootstrap_type='random', block_length=12\n",
      "    - B=30, bootstrap_type='random', block_length=24\n",
      "    - B=30, bootstrap_type='moving', block_length=6\n",
      "    - B=30, bootstrap_type='moving', block_length=12\n",
      "    - B=30, bootstrap_type='moving', block_length=24\n",
      "    - B=30, bootstrap_type='circular', block_length=6\n",
      "    - B=30, bootstrap_type='circular', block_length=12\n",
      "    - B=30, bootstrap_type='circular', block_length=24\n",
      "\n",
      "  - train_fraction=0.8\n",
      "    - B=30, bootstrap_type='random', block_length=6\n",
      "    - B=30, bootstrap_type='random', block_length=12\n",
      "    - B=30, bootstrap_type='random', block_length=24\n",
      "    - B=30, bootstrap_type='moving', block_length=6\n",
      "    - B=30, bootstrap_type='moving', block_length=12\n",
      "    - B=30, bootstrap_type='moving', block_length=24\n",
      "    - B=30, bootstrap_type='circular', block_length=6\n",
      "    - B=30, bootstrap_type='circular', block_length=12\n",
      "    - B=30, bootstrap_type='circular', block_length=24\n",
      "CPU times: user 3min 26s, sys: 2min 7s, total: 5min 34s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Execute!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "enbpi_exec(\n",
    "    # Step 1) Extract and Clean Data\n",
    "    data_list=data_list,\n",
    "    max_data_size=max_data_size,\n",
    "    # Step 2) Preprocess Data\n",
    "    train_fractions=train_fractions,\n",
    "    one_dim_list=one_dim_list,\n",
    "    n_lags=n_lags,\n",
    "    # Step 3) Preprocess Data\n",
    "    itrial=itrial,\n",
    "    B_list=B_list,\n",
    "    bootstrap_types=bootstrap_types,\n",
    "    block_lengths=block_lengths,\n",
    "    # STEP 4) Train Bootstrapped Models\n",
    "    model_types=model_types,\n",
    "    method=method,\n",
    "    # STEP 6) Get Conformal Prediction Interval\n",
    "    alphas=alphas,\n",
    "    # STEP 8) Output Results\n",
    "    output_name=output_name,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270497b-1026-4909-b16e-bdb3cb8190d0",
   "metadata": {},
   "source": [
    "# Function with Beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d67eb54-6604-44f1-ae07-29dbd30741ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main executable function\n",
    "\n",
    "def enbpi_exec_beta(\n",
    "    data_list,\n",
    "    max_data_size,\n",
    "    method,\n",
    "    train_fractions,\n",
    "    B_list,\n",
    "    bootstrap_types,\n",
    "    block_lengths,\n",
    "    model_types,\n",
    "    alphas,\n",
    "    itrial=0,\n",
    "    one_dim_list=[False],\n",
    "    n_lags=1,\n",
    "    output_name = output_name,\n",
    "    verbose=1,\n",
    "):\n",
    "\n",
    "    # Step 1) Extract and Clean Data\n",
    "    for data_name in data_list:\n",
    "        if verbose >= 1: \n",
    "            print(\"\\n\\n\" + \"=\"*80)\n",
    "            print(f\"data_name='{data_name}'\")\n",
    "        data_df, target_column = read_data(data_name, max_data_size)\n",
    "        tab_str = \"- \"\n",
    "        if verbose == 2:\n",
    "            print(f\"{tab_str}data_name shape:{data_df.shape}\")\n",
    "            print(f\"{tab_str}target_column='{target_column}'\")\n",
    "\n",
    "        # STEP 2): Preprocess Data ################    \n",
    "        for one_dim in one_dim_list:\n",
    "            if verbose >= 1: print(f\"\\n{tab_str}one_dim={one_dim}\")\n",
    "            # Separate results output for one_dim True and False\n",
    "            results_df = pd.DataFrame()\n",
    "            # results_df = pd.DataFrame(columns=_get_results_columns())\n",
    "            for train_fraction in train_fractions:\n",
    "                tab_str = \"  \" + tab_str\n",
    "                if verbose >= 1: print(f\"\\n{tab_str}train_fraction={train_fraction}\")\n",
    "                # 2a) Split train/test sets\n",
    "                # get X and y data\n",
    "                data_X = data_df.drop(target_column, axis=1)\n",
    "                data_y = data_df[target_column]\n",
    "                # convert X and y data to numpy\n",
    "                data_X_numpy = data_X.to_numpy()\n",
    "                data_y_numpy = data_y.to_numpy()\n",
    "                # get train idx to split train and test\n",
    "                train_size = int(len(data_df) * train_fraction)\n",
    "                # split into 4\n",
    "                X_train_numpy = data_X_numpy[:train_size, :]\n",
    "                X_test_numpy = data_X_numpy[train_size:, :]\n",
    "                y_train_numpy = data_y_numpy[:train_size]\n",
    "                y_test_numpy = data_y_numpy[train_size:]\n",
    "                # 2b) Get AR coeffs (optional)\n",
    "                if one_dim:\n",
    "                    X_train, X_test, y_train, y_test = one_dimen_transform(\n",
    "                        y_train_numpy,\n",
    "                        y_test_numpy,\n",
    "                        n_lags=n_lags,  # d\n",
    "                    )\n",
    "                else:\n",
    "                    X_train = X_train_numpy.copy()\n",
    "                    X_test = X_test_numpy.copy()\n",
    "                    y_train = y_train_numpy.copy()\n",
    "                    y_test = y_test_numpy.copy()\n",
    "                tab_str = \"  \" + tab_str\n",
    "                if verbose == 2: \n",
    "                    print(f\"{tab_str}X_train shape: {X_train.shape}\")\n",
    "                    print(f\"{tab_str}X_test shape: {X_test.shape}\")\n",
    "                    print(f\"{tab_str}y_train shape: {y_train.shape}\")\n",
    "                    print(f\"{tab_str}y_test shape: {y_test.shape}\")\n",
    "\n",
    "                # STEP 3) Bootstrap Synthetic Data ################\n",
    "                for B in B_list:\n",
    "                    for bootstrap_type in bootstrap_types:\n",
    "                        for block_length in block_lengths:\n",
    "                            if verbose >= 1:\n",
    "                                print(f\"{tab_str}B={B}, bootstrap_type='{bootstrap_type}', block_length={block_length}\")\n",
    "                            n = len(X_train)\n",
    "                            n1 = len(X_test)\n",
    "                            m = n\n",
    "                            # tot_trial = 1    # For CP method that randomizes (for EnbPI, should be set to 1)\n",
    "                            itrial = itrial  # for tot_trial in range(tot_trial)\n",
    "                            random_seed = B + itrial\n",
    "                            boot_samples_idx = generate_bootstrap_samples(\n",
    "                                n=n,\n",
    "                                m=m,\n",
    "                                B=B,\n",
    "                                bootstrap_type=bootstrap_type,\n",
    "                                block_length=block_length,\n",
    "                                random_seed=random_seed,\n",
    "                            )\n",
    "                            tab_str = \"  \" + tab_str\n",
    "                            if verbose == 2: print(f\"{tab_str}Bootstrap samples indexes shape: {boot_samples_idx.shape}\")\n",
    "                            # print(boot_samples_idx)\n",
    "\n",
    "                            # STEP 4) Train Bootstrapped Models ################\n",
    "                            # tab_str = \"  \" + tab_str    \n",
    "                            for model_type in model_types:\n",
    "                                # if verbose >= 1: print(f\"{tab_str}model_type='{model_type}'\")\n",
    "                                # hold predictions from each f^b\n",
    "                                boot_predictions = np.zeros((B, (n + n1)), dtype=float)\n",
    "                                # for i^th column, it shows which f^b uses i in training (so exclude in aggregation)\n",
    "                                in_boot_sample = np.zeros((B, n), dtype=bool)\n",
    "                                for b in range(B):\n",
    "                                    X_train_boot = X_train[boot_samples_idx[b], :]\n",
    "                                    y_train_boot = y_train[boot_samples_idx[b],]\n",
    "                                    model = initiate_regressor(model_type)\n",
    "                                    model.fit(\n",
    "                                        X_train_boot,\n",
    "                                        y_train_boot,\n",
    "                                        # epochs=10,\n",
    "                                        # batch_size=bsize,\n",
    "                                        # callbacks=[callback],\n",
    "                                        # verbose=0,\n",
    "                                    )\n",
    "                                    # Model's prediction for every observation on every bootstrapped data\n",
    "                                    boot_predictions[b] = model.predict(np.r_[X_train, X_test]).flatten()\n",
    "                                    # Whether a observation in the training data is sampled for the given bootstrapped data\n",
    "                                    # If it is true, then this observation should NOT be used for model prediction\n",
    "                                    in_boot_sample[b, boot_samples_idx[b]] = True\n",
    "                                tab_str = \"  \" + tab_str\n",
    "                                if verbose == 2:\n",
    "                                    print(f\"{tab_str}boot_predictions shape: {boot_predictions.shape}\")\n",
    "                                    print(f\"{tab_str}in_boot_sample shape: {in_boot_sample.shape}\")\n",
    "\n",
    "                                # STEP 5) LOO Predict and Mean Aggregate\n",
    "                                y_in_pred = np.zeros(n)          # Mean aggregated predict on in-sample train set\n",
    "                                y_LOO_preds = np.zeros((n, n1))  # Non-aggregated predict on OOS test set\n",
    "                                y_pred = np.zeros(n1)            # Aggregated predict on OOS test set\n",
    "\n",
    "                                ensemble_online_resid = np.array([])    # LOO scores\n",
    "                                # LOO in-sample train predict and OOS test predict \n",
    "                                for i in range(n):\n",
    "                                    b_keep = np.argwhere(~(in_boot_sample[:, i])).reshape(-1)\n",
    "                                    if len(b_keep) > 0:\n",
    "                                        # Get the LOO predictions for i for both in-sample and OOS\n",
    "                                        y_train_LOO_boot_preds = boot_predictions[b_keep, i]\n",
    "                                        y_in_pred[i] = y_train_LOO_boot_preds.mean()  # Mean aggregate to form a scalar value\n",
    "                                        y_LOO_boot_preds = boot_predictions[b_keep, n:]\n",
    "                                        y_LOO_preds[i] = y_LOO_boot_preds.mean(0)\n",
    "                                    else:  # if aggregating an empty set of models, predict zero everywhere\n",
    "                                        if verbose == 2: print(f\"{tab_str}  WARNING: no bootstrapped models available for i={i}\")\n",
    "                                y_pred = y_LOO_preds.mean(0)\n",
    "                                if verbose == 2:\n",
    "                                    print(f\"{tab_str}y_in_pred shape: {y_in_pred.shape}\")\n",
    "                                    print(f\"{tab_str}y_pred shape: {y_pred.shape}\")\n",
    "                                    print(f\"{tab_str}  y_LOO_preds shape: {y_LOO_preds.shape}\")\n",
    "\n",
    "                                # STEP 6) Aggregate Model with LOO\n",
    "                                for alpha in alphas:\n",
    "                                    # if verbose >= 1: print(f\"{tab_str}alpha={alpha}\")\n",
    "                                    # Get residual and sort\n",
    "                                    past_resid = np.subtract(y_train, y_in_pred)\n",
    "                                    past_resid.sort()\n",
    "                                    # Get beta-hat value and upper/lower bound\n",
    "                                    beta_hat = binning(past_resid, alpha = alpha)\n",
    "                                    upper_q = np.percentile(past_resid, math.ceil(100 * (1 - alpha + beta_hat)))\n",
    "                                    lower_q = np.percentile(past_resid, math.ceil(100 * beta_hat))\n",
    "                                    # Evaluation metric 1: PI width\n",
    "                                    width = upper_q - lower_q\n",
    "                                    tab_str = \"  \" + tab_str\n",
    "                                    if verbose == 2: print(f\"{tab_str}width={width}\")\n",
    "\n",
    "                                    # STEP 7) Get Coverage Rate from Test\n",
    "                                    # Get OOS residual and sort\n",
    "                                    oos_resid = np.subtract(y_test, y_pred)\n",
    "                                    oos_resid.sort()\n",
    "                                    # Count number of residuals below or equal to q_hat, or within the interval width.\n",
    "                                    n_coverage = np.asarray((oos_resid >= lower_q) & (oos_resid <= upper_q)).sum()\n",
    "                                    # Evaluation metric 2: Coverage rate\n",
    "                                    coverage = round(n_coverage/n1, 6)\n",
    "                                    if verbose == 2: print(f\"{tab_str}coverage={coverage}\")\n",
    "                                    \"\"\"\n",
    "                                    NOTE: I am using the symmetical conformal prediction (like in NP), instead of the\n",
    "                                          fancy method that Chen did. That is why the coverage rate is near the \n",
    "                                          theroretical guarantee limit of 2*alpha.\n",
    "                                    \"\"\"\n",
    "\n",
    "                                    #### STEP 8) Output Results\n",
    "                                    results_row = {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"one_dim\": one_dim,\n",
    "                                        \"itrial\": itrial,\n",
    "                                        \"train_fraction\": train_fraction,\n",
    "                                        \"B\": B,\n",
    "                                        \"bootstrap_type\": bootstrap_type,\n",
    "                                        \"block_length\": block_length,\n",
    "                                        \"model_type\": model.__class__.__name__,  # \"muh_fun\"\n",
    "                                        \"method\": method,\n",
    "                                        \"alpha\": alpha,\n",
    "                                        \"width\": width,    \n",
    "                                        \"coverage\": coverage,\n",
    "                                    }\n",
    "                                    results_df = pd.concat([results_df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "\n",
    "                                    tab_str = tab_str[2:]\n",
    "                                tab_str = tab_str[2:]\n",
    "                            tab_str = tab_str[2:]\n",
    "                tab_str = tab_str[4:]\n",
    "\n",
    "    results_df.to_csv(f'Results/{output_name}_beta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5efdb-7ac3-4288-a262-6c41f674353f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute!\n",
    "\n",
    "enbpi_exec_beta(\n",
    "    # Step 1) Extract and Clean Data\n",
    "    data_list=data_list,\n",
    "    max_data_size=max_data_size,\n",
    "    # Step 2) Preprocess Data\n",
    "    train_fractions=train_fractions,\n",
    "    one_dim_list=one_dim_list,\n",
    "    n_lags=n_lags,\n",
    "    # Step 3) Preprocess Data\n",
    "    itrial=itrial,\n",
    "    B_list=B_list,\n",
    "    bootstrap_types=bootstrap_types,\n",
    "    block_lengths=block_lengths,\n",
    "    # STEP 4) Train Bootstrapped Models\n",
    "    model_types=model_types,\n",
    "    method=method,\n",
    "    # STEP 6) Get Conformal Prediction Interval\n",
    "    alphas=alphas,\n",
    "    # STEP 8) Output Results\n",
    "    output_name=output_name,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c42d61-4c52-4b7a-801d-5b53e49791cc",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a96a4c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>one_dim</th>\n",
       "      <th>itrial</th>\n",
       "      <th>train_fraction</th>\n",
       "      <th>B</th>\n",
       "      <th>bootstrap_type</th>\n",
       "      <th>block_length</th>\n",
       "      <th>model_type</th>\n",
       "      <th>method</th>\n",
       "      <th>alpha</th>\n",
       "      <th>width</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>425.379132</td>\n",
       "      <td>0.995814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>297.038506</td>\n",
       "      <td>0.936454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>425.140596</td>\n",
       "      <td>0.995814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>297.251918</td>\n",
       "      <td>0.936454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>421.683693</td>\n",
       "      <td>0.996195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>298.839197</td>\n",
       "      <td>0.973174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>431.629425</td>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>296.897144</td>\n",
       "      <td>0.973174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>415.441163</td>\n",
       "      <td>0.998288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>324.873289</td>\n",
       "      <td>0.993151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_name  one_dim  itrial  train_fraction   B bootstrap_type  \\\n",
       "0    Solar_Atl    False       0             0.7  30         random   \n",
       "1    Solar_Atl    False       0             0.7  30         random   \n",
       "2    Solar_Atl    False       0             0.7  30         random   \n",
       "3    Solar_Atl    False       0             0.7  30         random   \n",
       "4    Solar_Atl    False       0             0.7  30         random   \n",
       "..         ...      ...     ...             ...  ..            ...   \n",
       "103  Solar_Atl    False       0             0.8  30       circular   \n",
       "104  Solar_Atl    False       0             0.8  30       circular   \n",
       "105  Solar_Atl    False       0             0.8  30       circular   \n",
       "106  Solar_Atl    False       0             0.8  30       circular   \n",
       "107  Solar_Atl    False       0             0.8  30       circular   \n",
       "\n",
       "     block_length             model_type    method  alpha       width  \\\n",
       "0               6                LassoCV  Ensemble   0.05  425.379132   \n",
       "1               6                LassoCV  Ensemble   0.10  297.038506   \n",
       "2               6                RidgeCV  Ensemble   0.05  425.140596   \n",
       "3               6                RidgeCV  Ensemble   0.10  297.251918   \n",
       "4               6  RandomForestRegressor  Ensemble   0.05  421.683693   \n",
       "..            ...                    ...       ...    ...         ...   \n",
       "103            24                LassoCV  Ensemble   0.10  298.839197   \n",
       "104            24                RidgeCV  Ensemble   0.05  431.629425   \n",
       "105            24                RidgeCV  Ensemble   0.10  296.897144   \n",
       "106            24  RandomForestRegressor  Ensemble   0.05  415.441163   \n",
       "107            24  RandomForestRegressor  Ensemble   0.10  324.873289   \n",
       "\n",
       "     coverage  \n",
       "0    0.995814  \n",
       "1    0.936454  \n",
       "2    0.995814  \n",
       "3    0.936454  \n",
       "4    0.996195  \n",
       "..        ...  \n",
       "103  0.973174  \n",
       "104  0.995434  \n",
       "105  0.973174  \n",
       "106  0.998288  \n",
       "107  0.993151  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output of original function\n",
    "df_original = pd.read_csv(f'Results/Solar_Atl_original.csv')\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa1e8169-34f8-4e65-b3e3-20497f9eb9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>one_dim</th>\n",
       "      <th>itrial</th>\n",
       "      <th>train_fraction</th>\n",
       "      <th>B</th>\n",
       "      <th>bootstrap_type</th>\n",
       "      <th>block_length</th>\n",
       "      <th>model_type</th>\n",
       "      <th>method</th>\n",
       "      <th>alpha</th>\n",
       "      <th>width</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>386.662517</td>\n",
       "      <td>0.954718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>308.746353</td>\n",
       "      <td>0.928463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>387.025215</td>\n",
       "      <td>0.955099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>308.945867</td>\n",
       "      <td>0.928843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>394.726228</td>\n",
       "      <td>0.976027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>310.173160</td>\n",
       "      <td>0.988014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>391.309954</td>\n",
       "      <td>0.999429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>309.696485</td>\n",
       "      <td>0.988014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.05</td>\n",
       "      <td>403.255244</td>\n",
       "      <td>0.999429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Solar_Atl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>circular</td>\n",
       "      <td>24</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.10</td>\n",
       "      <td>316.861897</td>\n",
       "      <td>0.994292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_name  one_dim  itrial  train_fraction   B bootstrap_type  \\\n",
       "0    Solar_Atl    False       0             0.7  30         random   \n",
       "1    Solar_Atl    False       0             0.7  30         random   \n",
       "2    Solar_Atl    False       0             0.7  30         random   \n",
       "3    Solar_Atl    False       0             0.7  30         random   \n",
       "4    Solar_Atl    False       0             0.7  30         random   \n",
       "..         ...      ...     ...             ...  ..            ...   \n",
       "103  Solar_Atl    False       0             0.8  30       circular   \n",
       "104  Solar_Atl    False       0             0.8  30       circular   \n",
       "105  Solar_Atl    False       0             0.8  30       circular   \n",
       "106  Solar_Atl    False       0             0.8  30       circular   \n",
       "107  Solar_Atl    False       0             0.8  30       circular   \n",
       "\n",
       "     block_length             model_type    method  alpha       width  \\\n",
       "0               6                LassoCV  Ensemble   0.05  386.662517   \n",
       "1               6                LassoCV  Ensemble   0.10  308.746353   \n",
       "2               6                RidgeCV  Ensemble   0.05  387.025215   \n",
       "3               6                RidgeCV  Ensemble   0.10  308.945867   \n",
       "4               6  RandomForestRegressor  Ensemble   0.05  394.726228   \n",
       "..            ...                    ...       ...    ...         ...   \n",
       "103            24                LassoCV  Ensemble   0.10  310.173160   \n",
       "104            24                RidgeCV  Ensemble   0.05  391.309954   \n",
       "105            24                RidgeCV  Ensemble   0.10  309.696485   \n",
       "106            24  RandomForestRegressor  Ensemble   0.05  403.255244   \n",
       "107            24  RandomForestRegressor  Ensemble   0.10  316.861897   \n",
       "\n",
       "     coverage  \n",
       "0    0.954718  \n",
       "1    0.928463  \n",
       "2    0.955099  \n",
       "3    0.928843  \n",
       "4    0.976027  \n",
       "..        ...  \n",
       "103  0.988014  \n",
       "104  0.999429  \n",
       "105  0.988014  \n",
       "106  0.999429  \n",
       "107  0.994292  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta = pd.read_csv(f'Results/Solar_Atl_beta.csv')\n",
    "df_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf9462b8-9131-4ae8-a059-8e930e94e777",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>model_type</th>\n",
       "      <th>bootstrap_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LassoCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>430.050849</td>\n",
       "      <td>0.996100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>428.647722</td>\n",
       "      <td>0.995941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>428.740926</td>\n",
       "      <td>0.995624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RandomForestRegressor</th>\n",
       "      <th>circular</th>\n",
       "      <td>418.948579</td>\n",
       "      <td>0.997019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>419.116547</td>\n",
       "      <td>0.997083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>417.246215</td>\n",
       "      <td>0.996956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RidgeCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>429.372725</td>\n",
       "      <td>0.995688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>428.784298</td>\n",
       "      <td>0.995592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>428.540379</td>\n",
       "      <td>0.995624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LassoCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>297.852903</td>\n",
       "      <td>0.955448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>297.865922</td>\n",
       "      <td>0.955765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>295.268998</td>\n",
       "      <td>0.954243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RandomForestRegressor</th>\n",
       "      <th>circular</th>\n",
       "      <td>328.941831</td>\n",
       "      <td>0.980784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>329.879879</td>\n",
       "      <td>0.981037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>327.875481</td>\n",
       "      <td>0.981355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RidgeCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>297.461988</td>\n",
       "      <td>0.955702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>297.868664</td>\n",
       "      <td>0.956019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>295.396543</td>\n",
       "      <td>0.954243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 width  coverage\n",
       "alpha model_type            bootstrap_type                      \n",
       "0.05  LassoCV               circular        430.050849  0.996100\n",
       "                            moving          428.647722  0.995941\n",
       "                            random          428.740926  0.995624\n",
       "      RandomForestRegressor circular        418.948579  0.997019\n",
       "                            moving          419.116547  0.997083\n",
       "                            random          417.246215  0.996956\n",
       "      RidgeCV               circular        429.372725  0.995688\n",
       "                            moving          428.784298  0.995592\n",
       "                            random          428.540379  0.995624\n",
       "0.10  LassoCV               circular        297.852903  0.955448\n",
       "                            moving          297.865922  0.955765\n",
       "                            random          295.268998  0.954243\n",
       "      RandomForestRegressor circular        328.941831  0.980784\n",
       "                            moving          329.879879  0.981037\n",
       "                            random          327.875481  0.981355\n",
       "      RidgeCV               circular        297.461988  0.955702\n",
       "                            moving          297.868664  0.956019\n",
       "                            random          295.396543  0.954243"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.groupby(by = ['alpha', 'model_type', 'bootstrap_type']).mean()[['width', 'coverage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efeac745-750a-4f31-b202-789acc727ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>model_type</th>\n",
       "      <th>bootstrap_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LassoCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>389.449364</td>\n",
       "      <td>0.978279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>389.488445</td>\n",
       "      <td>0.978279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>387.854710</td>\n",
       "      <td>0.977073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RandomForestRegressor</th>\n",
       "      <th>circular</th>\n",
       "      <td>400.397012</td>\n",
       "      <td>0.988679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>400.405404</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>399.719919</td>\n",
       "      <td>0.987728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RidgeCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>389.424287</td>\n",
       "      <td>0.978215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>389.659741</td>\n",
       "      <td>0.978722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>388.090670</td>\n",
       "      <td>0.977264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LassoCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>309.524936</td>\n",
       "      <td>0.959316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>309.716825</td>\n",
       "      <td>0.959760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>308.348200</td>\n",
       "      <td>0.958238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RandomForestRegressor</th>\n",
       "      <th>circular</th>\n",
       "      <td>317.713341</td>\n",
       "      <td>0.979642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>317.972402</td>\n",
       "      <td>0.979293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>318.685734</td>\n",
       "      <td>0.978310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RidgeCV</th>\n",
       "      <th>circular</th>\n",
       "      <td>309.620928</td>\n",
       "      <td>0.959443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving</th>\n",
       "      <td>309.668102</td>\n",
       "      <td>0.959824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>308.426896</td>\n",
       "      <td>0.958429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 width  coverage\n",
       "alpha model_type            bootstrap_type                      \n",
       "0.05  LassoCV               circular        389.449364  0.978279\n",
       "                            moving          389.488445  0.978279\n",
       "                            random          387.854710  0.977073\n",
       "      RandomForestRegressor circular        400.397012  0.988679\n",
       "                            moving          400.405404  0.988426\n",
       "                            random          399.719919  0.987728\n",
       "      RidgeCV               circular        389.424287  0.978215\n",
       "                            moving          389.659741  0.978722\n",
       "                            random          388.090670  0.977264\n",
       "0.10  LassoCV               circular        309.524936  0.959316\n",
       "                            moving          309.716825  0.959760\n",
       "                            random          308.348200  0.958238\n",
       "      RandomForestRegressor circular        317.713341  0.979642\n",
       "                            moving          317.972402  0.979293\n",
       "                            random          318.685734  0.978310\n",
       "      RidgeCV               circular        309.620928  0.959443\n",
       "                            moving          309.668102  0.959824\n",
       "                            random          308.426896  0.958429"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta.groupby(by = ['alpha', 'model_type', 'bootstrap_type']).mean()[['width', 'coverage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e223ff93",
   "metadata": {},
   "source": [
    "# If using noneoverlapping BB, use this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcad820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "# Step 1) params\n",
    "# cali_cities = [\"Palo_Alto\"]\n",
    "# data_list = _get_cali_cities()\n",
    "# data_list = [\"Solar_Atl\"] + cali_cities + [\"appliances\", \"Beijing_air\"]\n",
    "data_list = [\"Solar_Atl\"]\n",
    "max_data_size = 10000\n",
    "\n",
    "# Step 2) params\n",
    "train_fractions = [0.8001]\n",
    "# train_fractions = [0.1, 0.2]\n",
    "# train_fractions = [0.5, 0.6, 0.7, 0.8]\n",
    "# train_fractions = [0.3, 0.4, 0.5, 0.6, 0.7]  # EnbPI WP Pg. 8\n",
    "# print(train_fractions)\n",
    "# one_dim_list = [True]\n",
    "one_dim_list = [False]\n",
    "n_lags = 24  # 'n_lags' aka 'd` is num_lookbacks for AR-transformer\n",
    "\n",
    "# Step 3) params\n",
    "itrial = 0\n",
    "B_list = [30]  # number of bootstraps list\n",
    "# B_list = [20, 25, 30, 35, 40, 45, 50]  # EnbPI WP Pg. 11: between 20-50 is sufficient\n",
    "# bootstrap_types = [\"random\", \"moving\"]  # \"nonoverlapping\" has problem -> IndexError: index 851 is out of bounds for axis 0 with size 851\n",
    "# bootstrap_types = [\"random\", \"moving\", \"circular\", \"stationary\"]\n",
    "bootstrap_types = [\"random\", \"moving\", \"nonoverlapping\"]\n",
    "block_lengths = [6, 12, 24]\n",
    "# block_lengths = [6, 12, 24, 48, 60, 72]\n",
    "\n",
    "# Step 4) params\n",
    "# model_types = [\"ridge\", \"random_forest\"]  # muh_fun\n",
    "model_types = [\"lasso\", \"ridge\", \"random_forest\"]  # \"neural_networks\"\n",
    "method = \"Ensemble\"\n",
    "\n",
    "# Step 6) params\n",
    "alphas = [0.05, 0.1, 0.15]\n",
    "# alphas = [0.05, 0.1, 0.15, 0.2, 0.25]  # EnbPI WP Pg. 17: five equally spaces 1-a [0.75, 0.95] are chosen\n",
    "# alphas = [0.01, 0.10, 0.20, 0.50, 0.80, 0.90, 0.99]\n",
    "# alphas = [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.50, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99]\n",
    "\n",
    "# Step 8) params\n",
    "output_name = \"Solar_Atl_NBB\"\n",
    "verbose = 1  # 0 no print statement, 1 only params, 2 everything"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peter:Python",
   "language": "python",
   "name": "conda-env-peter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
